{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:30px;font-weight:bold\">Clause Syntax in the Song of Songs:<br><br> A Preliminary Study</p>\n",
    "<br>\n",
    "<br>\n",
    "# Song of Songs Clause Statistics\n",
    "<strong>Purpose of this search:</strong>\n",
    "<br>\n",
    "<br>\n",
    "This search produces clause statistics on mainline clauses for the Song of Songs. The clause use statistics are calculated both for the book as a whole and chapter by chapter. Additional statistics are calculated such as standard deviation for different clause types, as well as the coefficient of variation, to measure clause use consistency.\n",
    "<br>\n",
    "<br>\n",
    "For the purpose of this study, \"mainline\" clauses are those which are not adverbial or adjectival. Clauses such as vocatives, ellipses, casus pendens, and defective are excluded. Also, clauses stored as \"AjCl\" in ETCBC are considered nominal clauses for the purpose here.\n",
    "<br>\n",
    "<br>\n",
    "In this notebook, statistics are printed to the console. However, simple modifications to the search could write results to a CSV, txt file, or HTML display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.21\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imports the modules needed for the search\n",
    "\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "#imports the LAF-Fabric modules\n",
    "\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric(verbose = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  3.97s LOGFILE=/Users/Cody/laf-fabric-output/etcbc4b/clause_stats/__log__clause_stats.txt\n",
      "  3.97s INFO: LOADING PREPARED data: please wait ... \n",
      "  3.97s prep prep: G.node_sort\n",
      "  4.11s prep prep: G.node_sort_inv\n",
      "  4.79s prep prep: L.node_up\n",
      "  8.64s prep prep: L.node_down\n",
      " 4h 51m 42s END\n",
      "    21s prep prep: V.verses\n",
      "    21s prep prep: V.books_la\n",
      "    21s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    24s INFO: LOADED PREPARED data\n",
      "    24s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK clause_stats AT 2016-04-08T22-10-47\n"
     ]
    }
   ],
   "source": [
    "#loads the data into the processor; \"features\" refers to types of data stored in the ETCBC database. \n",
    "#The various features can be accessed at \n",
    "# https://shebanq.ancient-data.org/shebanq/static/docs/featuredoc/features/comments/0_overview.html\n",
    "\n",
    "API = fabric.load('etcbc4b','--','clause_stats',\n",
    "\n",
    "                  {'primary': False,\n",
    "                   'xmlids':{'node':False,'edge':False},\n",
    "                   'features':('book chapter verse otype code typ txt monads',''),\n",
    "                   'prepare': prepare\n",
    "        \n",
    "                    }\n",
    ")\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Functions:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#retrieves book, chapter, or verse information for a given node\n",
    "#uses the \"look up\" function provided by the ETCBC package of modules\n",
    "#see http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
    "def get_ref(ref_type,node):\n",
    "    if ref_type == 'verse':\n",
    "        verse = L.u('verse',node)\n",
    "        return F.verse.v(verse)\n",
    "    elif ref_type == 'chapter':\n",
    "        chapter = L.u('chapter',node)\n",
    "        return F.chapter.v(chapter)\n",
    "    elif ref_type == 'book':\n",
    "        book = L.u('book',node)\n",
    "        return F.book.v(book)\n",
    "    \n",
    "#returns a percentage between a total and a frequency\n",
    "def get_percent(total,freq):\n",
    "    return str(round((float(freq / total)*100),2))+'%'\n",
    "\n",
    "#receives a clause_atom node, checks its code and returns only mainline clause types\n",
    "#for this search, mainline is defined as asyndetic, parallel, coordinate with ו or או and direct speech (999)\n",
    "def code_filter(node):\n",
    "    \n",
    "    code = int(F.code.v(node))\n",
    "    \n",
    "    #asyndetic\n",
    "\n",
    "    if 100 <= code <= 167:\n",
    "        return True\n",
    "    \n",
    "    #parallel\n",
    "    elif 200 <= code <= 201:\n",
    "        return True\n",
    "    \n",
    "    #asyndetic with conj.\n",
    "    elif 300 <= code <= 367:\n",
    "        return True\n",
    "    \n",
    "    #syndetic\n",
    "    elif 400 <= code <= 487:\n",
    "        return True\n",
    "    \n",
    "    #first cl in direct speech\n",
    "    elif code == 999:\n",
    "        return True\n",
    "    \n",
    "#provides a simplified identifier for clause types\n",
    "def simple_type(typ):\n",
    "    \n",
    "    simple_type = None\n",
    "    \n",
    "    simplified = {'way' : [\"Way0\", \"WayX\"],\n",
    "                  'nmcl' : [\"NmCl\",\"AjCl\"],\n",
    "                  'ptc' : [\"Ptcp\"],\n",
    "                  'qtl' : [\"WQt0\", \"WQtX\", \"WxQ0\", \"WXQt\", \"WxQX\", \"xQt0\", \"XQtl\", \"xQtX\", \"ZQt0\", \"ZQtX\"],\n",
    "                  'yqtl' : [\"WxY0\", \"WXYq\", \"WxYX\", \"WYq0\", \"WYqX\", \"xYq0\", \"XYqt\", \"xYqX\", \"ZYq0\", \"ZYqX\"],\n",
    "                  'impv' : [\"WIm0\",\"WImX\", \"WxI0\", \"WXIm\", \"WxIX\", \"xIm0\", \"XImp\", \"xImX\", \"ZIm0\", \"ZImX\"],\n",
    "                 }\n",
    "\n",
    "    for key in simplified:\n",
    "        if typ in simplified[key]:\n",
    "            simple_type = key\n",
    "            \n",
    "    return simple_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Data retrieval:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4.51s 6020 nodes appended\n"
     ]
    }
   ],
   "source": [
    "#indexes all nodes in the Song of Songs to facilitate faster searches\n",
    "#SongofSongs nodes are stored in \"nodes\" list\n",
    "\n",
    "corpus = [\"Canticum\"]\n",
    "\n",
    "cur_book = None\n",
    "nodes = []\n",
    "\n",
    "for n in NN():\n",
    "    if cur_book in corpus:\n",
    "        nodes.append(n)\n",
    "    \n",
    "    if F.otype.v(n) == 'book':\n",
    "        cur_book = F.book.v(n)\n",
    "        \n",
    "msg('{} nodes appended'.format(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#retrieves the last relevant clause atom node in the Song of Songs\n",
    "#this node will provide a reference point for the chapter by chapter search below \n",
    "#when the loop hits this node, the code will assemble the data for the final chapter (since there is no chapter marker\n",
    "#to trigger the final compilation)\n",
    "\n",
    "#last_node is reset for each clause atom until it loops through all nodes in Song of Song\n",
    "#this leaves the last node as the variable last_node\n",
    "last_node = None\n",
    "\n",
    "for n in nodes:\n",
    "    otype = F.otype.v(n)\n",
    "    if otype == 'clause_atom' and code_filter(n) == True and simple_type(F.typ.v(n)) != None:\n",
    "        last_node = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5.95s 8 chapters logged\n"
     ]
    }
   ],
   "source": [
    "#current chapter\n",
    "cur_chapter = None\n",
    "\n",
    "#if chapter_check does not equal cur_chapter, it initiates the compilation of occurrences for the chapter \n",
    "#resets to cur_chapter after compilation\n",
    "chapter_check = None\n",
    "\n",
    "\n",
    "ch_clauses = []\n",
    "occurrences = collections.OrderedDict([('total',0)])\n",
    "results = collections.OrderedDict([])\n",
    "\n",
    "for n in nodes:\n",
    "    \n",
    "    #assigns otype feature to a variable\n",
    "    otype = F.otype.v(n)\n",
    "    \n",
    "    if otype == 'chapter':\n",
    "        \n",
    "        #sets current chapter\n",
    "        cur_chapter = F.chapter.v(n)\n",
    "        \n",
    "        #chapter_check is called for each clause atom; sets to current chapter if loop has just started \n",
    "        if chapter_check == None:\n",
    "            chapter_check = F.chapter.v(n)\n",
    "    \n",
    "    if otype == 'clause_atom':\n",
    "        \n",
    "        #checks to see if clause atom is a mainline clause\n",
    "        if code_filter(n) == True and simple_type(F.typ.v(n)) != None:\n",
    "            \n",
    "            #converts clause code to simplified form (i.e. qtl, yqtl, etc.)\n",
    "            clause = simple_type(F.typ.v(n))\n",
    "            \n",
    "            #has the chapter changed or the book ended? if same chapter, append clause to ch_clauses list\n",
    "            #ch_clauses acts as a staging area until the chapter changes \n",
    "            if get_ref('chapter',n) == chapter_check and n != last_node:\n",
    "                ch_clauses.append(clause)\n",
    "            \n",
    "            #if chapter is different or the node is the last node\n",
    "            else:\n",
    "                \n",
    "                #checks to see if this is the last node; appends clause if true\n",
    "                if n == last_node:\n",
    "                    ch_clauses.append(clause)\n",
    "        \n",
    "                #assembles frequency data for the chapter\n",
    "                for clause in ch_clauses:\n",
    "                    occurrences['total'] += 1\n",
    "                    if clause in occurrences:\n",
    "                        occurrences[clause] += 1\n",
    "                    else:\n",
    "                        occurrences[clause] = 1\n",
    "                        \n",
    "                #orders occurrences from greatest to least\n",
    "                occurrences = collections.OrderedDict(sorted(occurrences.items(),key=lambda t: t[1],reverse = True))\n",
    "                \n",
    "                #adds any missing clause types into occurrences with '0'\n",
    "                types = ['nmcl','qtl','yqtl','impv','ptc','way']\n",
    "                for typ in types:\n",
    "                    if typ not in occurrences:\n",
    "                        occurrences[typ] = 0\n",
    "                \n",
    "                #drops clause occurrences for the chapter into results\n",
    "                for key in occurrences:\n",
    "                    if chapter_check in results:\n",
    "                        results[chapter_check].append([key,occurrences[key]])\n",
    "                    else:\n",
    "                        results[chapter_check] = [[key,occurrences[key]]]\n",
    "                \n",
    "                #resets variables for next chapter\n",
    "                chapter_check = cur_chapter\n",
    "                ch_clauses = []\n",
    "                occurrences = collections.OrderedDict([('total',0)])\n",
    "                \n",
    "                #logs data for current chapter\n",
    "                ch_clauses.append(clause)\n",
    "                \n",
    "msg(str(len(results))+' chapters logged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Now the clause data for each chapter is assembled. Time to present the results:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song of Songs\n",
      "----------\n",
      "1  nmcl     120   36.59%\n",
      "2   qtl      83   25.3%\n",
      "3  yqtl      58   17.68%\n",
      "4  impv      34   10.37%\n",
      "5   ptc      31   9.45%\n",
      "6   way       2   0.61%\n",
      "\n",
      "\n",
      "chapter 1\n",
      "----------\n",
      "1  nmcl      14   36.84%\n",
      "2  yqtl      11   28.95%\n",
      "3   qtl       8   21.05%\n",
      "4  impv       4   10.53%\n",
      "5   ptc       1   2.63%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 2\n",
      "----------\n",
      "1   qtl      14   29.79%\n",
      "2  nmcl      12   25.53%\n",
      "3  impv      11   23.4%\n",
      "4   ptc       8   17.02%\n",
      "5  yqtl       2   4.26%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 3\n",
      "----------\n",
      "1   qtl       9   34.62%\n",
      "2  nmcl       7   26.92%\n",
      "3  yqtl       5   19.23%\n",
      "4  impv       3   11.54%\n",
      "5   ptc       2   7.69%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 4\n",
      "----------\n",
      "1  nmcl      25   58.14%\n",
      "2  yqtl       7   16.28%\n",
      "3   qtl       5   11.63%\n",
      "4  impv       4    9.3%\n",
      "5   ptc       2   4.65%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 5\n",
      "----------\n",
      "1   qtl      21   35.0%\n",
      "2  nmcl      21   35.0%\n",
      "3   ptc      10   16.67%\n",
      "4  yqtl       4   6.67%\n",
      "5  impv       4   6.67%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 6\n",
      "----------\n",
      "1  nmcl      19   63.33%\n",
      "2   qtl       7   23.33%\n",
      "3   way       2   6.67%\n",
      "4  yqtl       1   3.33%\n",
      "5  impv       1   3.33%\n",
      "6   ptc       0    0.0%\n",
      "\n",
      "\n",
      "chapter 7\n",
      "----------\n",
      "1  nmcl      12   29.27%\n",
      "2  yqtl      11   26.83%\n",
      "3   qtl      10   24.39%\n",
      "4   ptc       5   12.2%\n",
      "5  impv       3   7.32%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n",
      "chapter 8\n",
      "----------\n",
      "1  yqtl      17   39.53%\n",
      "2  nmcl      10   23.26%\n",
      "3   qtl       9   20.93%\n",
      "4  impv       4    9.3%\n",
      "5   ptc       3   6.98%\n",
      "6   way       0    0.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#assembles occurrences for the whole book\n",
    "book_occ = collections.OrderedDict([('total',0)])\n",
    "for chapter in results:\n",
    "    for typ in results[chapter]:\n",
    "        if typ[0] == 'total':\n",
    "            book_occ['total'] += typ[1]\n",
    "        else:\n",
    "            if typ[0] in book_occ:\n",
    "                book_occ[typ[0]] += typ[1]\n",
    "            else:\n",
    "                book_occ[typ[0]] = typ[1]\n",
    "                \n",
    "#orders occurrences from highest to lowest\n",
    "book_occ = collections.OrderedDict(sorted(book_occ.items(),key=lambda t: t[1],reverse = True))\n",
    "\n",
    "#prints results for whole book\n",
    "print ('Song of Songs')\n",
    "print ('-'*10)\n",
    "counter = 0\n",
    "for typ in book_occ:\n",
    "    total = book_occ['total']\n",
    "    if typ != 'total':\n",
    "        counter += 1\n",
    "        print ('{} {:>5}   {:>5}   {:>5}'.format(counter,typ, book_occ[typ],get_percent(total,book_occ[typ])))\n",
    "print ('\\n')\n",
    "\n",
    "#prints results by chapter\n",
    "for chapter in results:\n",
    "    counter = -1\n",
    "    \n",
    "    ch_stats = collections.OrderedDict()\n",
    "    print ('chapter ' + chapter)\n",
    "    print ('-'*10)\n",
    "    total = 0\n",
    "    for typ in results[chapter]:\n",
    "        if typ[0] == 'total':\n",
    "            total = typ[1]\n",
    "    for typ in results[chapter]:\n",
    "        counter += 1\n",
    "        if typ[0] != 'total':\n",
    "            print ('{} {:>5}   {:>5}   {:>5}'.format(counter,typ[0], typ[1],get_percent(total,typ[1])))\n",
    "        \n",
    "    print ('\\n')\n",
    "    \n",
    "#of course, results might also be written to a CSV or txt file or displayed with HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#redefines get_percent so that it does not round, convert to string, and add a % sign\n",
    "def get_percent(total1,total2):\n",
    "    return (float(total2 / total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pairs clause types (i.e., qtl, yqtl, etc.) with their chapter by chapter percentages so that the mean \n",
    "#can be calculated for the standard deviation\n",
    "\n",
    "#type_percents contains clause types as keys\n",
    "#each clause type key has a list as a value with chapter by chapter percentages\n",
    "#ex: 'nmcl': [36.84,25.53,26.92,58.14,35.00,63.33,29.27,23.26]\n",
    "#thus each value contains 8 percentages for all 8 chapters in the Song\n",
    "type_percents = collections.OrderedDict()\n",
    "\n",
    "#calculates and appends chapter by chapter percentages\n",
    "for chapter in results:\n",
    "    total = 0\n",
    "    \n",
    "    #retrieves total for chapter so that percent can be calculated\n",
    "    for typ in results[chapter]:\n",
    "        if typ[0] == 'total': \n",
    "            total = typ[1]\n",
    "            \n",
    "    #retrieves total for clause types in the chapter and converts to percentage\n",
    "    for typ in results[chapter]:\n",
    "        if typ[0] in type_percents:\n",
    "            type_percents[typ[0]].append(get_percent(total,typ[1]))\n",
    "        elif typ[0] != 'total':\n",
    "            type_percents[typ[0]] = [get_percent(total,typ[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculates the mean for each clause type in type_percents:\n",
    "\n",
    "#type_mean pairs clause types with the mean percentage in the Song\n",
    "type_mean = collections.OrderedDict()\n",
    "\n",
    "for typ in type_percents:\n",
    "    total = 0.0\n",
    "    for percent in type_percents[typ]:\n",
    "        total += percent\n",
    "    mean = total / 8.0 #(number of chapters)\n",
    "    type_mean[typ] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculates variance for each clause type\n",
    "\n",
    "type_variance = collections.OrderedDict()\n",
    "\n",
    "for typ in type_percents:\n",
    "    pre_variance = 0.0\n",
    "    for percent in type_percents[typ]:\n",
    "        pre_variance += (percent-type_mean[typ])**2\n",
    "    \n",
    "    variance = pre_variance/8.0 #(number of chapters)\n",
    "    \n",
    "    type_variance[typ] = variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Now ready to print standard deviation:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviations:\n",
      "nmcl 14.25\n",
      "yqtl 12.24\n",
      "qtl   7.33\n",
      "impv  5.54\n",
      "ptc   5.89\n",
      "way    2.2\n"
     ]
    }
   ],
   "source": [
    "#calculates and prints standard deviation for each clause type\n",
    "\n",
    "type_stnd_dev = collections.OrderedDict()\n",
    "\n",
    "for typ in type_variance:\n",
    "    type_stnd_dev[typ] = math.sqrt(type_variance[typ])\n",
    "\n",
    "print('Standard Deviations:')\n",
    "for typ in type_stnd_dev:\n",
    "    print (\"{0:<5}{1:>5}\".format(typ,round(type_stnd_dev[typ],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Standard deviation allows for the coefficient of variation to be printed next:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of Variation:\n",
      "nmcl 38.96\n",
      "yqtl 69.21\n",
      "qtl  28.95\n",
      "impv 53.47\n",
      "ptc  62.31\n",
      "way  361.59\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients of Variation:')\n",
    "for typ in type_stnd_dev:\n",
    "    percent = float(book_occ[typ])/float(book_occ['total'])\n",
    "    coeff_var = round(type_stnd_dev[typ]/percent,2)\n",
    "    print (\"{0:<5}{1:>5}\".format(typ,coeff_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
