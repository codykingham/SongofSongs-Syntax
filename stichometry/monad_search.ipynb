{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.21\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections \n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "\n",
    "fabric = LafFabric(verbose='NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  4.61s LOGFILE=/Users/Cody/laf-fabric-output/etcbc4b/monad_search/__log__monad_search.txt\n",
      "  4.61s INFO: LOADING PREPARED data: please wait ... \n",
      "  4.61s prep prep: G.node_sort\n",
      "  4.73s prep prep: G.node_sort_inv\n",
      "  5.30s prep prep: L.node_up\n",
      "  9.13s prep prep: L.node_down\n",
      "    15s prep prep: V.verses\n",
      "    15s prep prep: V.books_la\n",
      "    15s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    18s INFO: LOADED PREPARED data\n",
      "    18s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK monad_search AT 2016-03-10T20-22-59\n"
     ]
    }
   ],
   "source": [
    "fabric.load('etcbc4b', '--', 'monad_search',\n",
    "{\n",
    "    \"xmlids\" : {\"node\": False, \"edge\" : False},\n",
    "    \"features\" : (\"oid otype monads chapter verse book g_word_utf8 trailer_utf8\",\"\"),\n",
    "    \"prepare\" : prepare\n",
    "}\n",
    "           )\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    15s 218647 nodes added\n"
     ]
    }
   ],
   "source": [
    "corpus = \"Canticum\"\n",
    "cur_book = None\n",
    "nodes = []\n",
    "for n in NN():\n",
    "    otype = F.otype.v(n)\n",
    "    if cur_book==corpus:\n",
    "        nodes.append(n)\n",
    "    elif otype == \"book\":\n",
    "        cur_book = F.book.v(n)\n",
    "msg(\"{} nodes added\".format(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 04s ( 1/52 )  (C.Ca)\n",
      " 1m 05s ( 2/52 )  (C.Ca)\n",
      " 1m 05s ( 3/52 )  (N)\n",
      " 1m 05s ( 4/52 )  (S.Sa.C.Ca)\n",
      " 1m 05s ( 5/52 )  (N)\n",
      " 1m 05s ( 6/52 )  (N)\n",
      " 1m 06s ( 7/52 )  (N)\n",
      " 1m 06s ( 8/52 )  (Pa)\n",
      " 1m 06s ( 9/52 )  (S.Sa.C.Ca)\n",
      " 1m 06s ( 10/52 )  (S.Sa.C.Ca)\n",
      " 1m 06s ( 11/52 )  (C.Ca)\n",
      " 1m 07s ( 12/52 )  (C.Ca.P.Pa)\n",
      " 1m 07s ( 13/52 )  (N)\n",
      " 1m 07s ( 14/52 )  (C.Ca)\n",
      " 1m 07s ( 15/52 )  (C.Ca)\n",
      " 1m 07s ( 16/52 )  (C.Ca)\n",
      " 1m 08s ( 17/52 )  (S.Sa.C.Ca)\n",
      " 1m 08s ( 18/52 )  (S.Sa.C.Ca)\n",
      " 1m 08s ( 19/52 )  (S.Sa)\n",
      " 1m 08s ( 20/52 )  (C.Ca)\n",
      " 1m 08s ( 21/52 )  (C.Ca)\n",
      " 1m 09s ( 22/52 )  (S.Sa.C.Ca)\n",
      " 1m 09s ( 23/52 )  (S.Sa.C.Ca)\n",
      " 1m 09s ( 24/52 )  (N)\n",
      " 1m 09s ( 25/52 )  (N)\n",
      " 1m 09s ( 26/52 )  (Hv)\n",
      " 1m 09s ( 27/52 )  (Hv)\n",
      " 1m 10s ( 28/52 )  (S.Sa.C.Ca)\n",
      " 1m 10s ( 29/52 )  (S.Sa.C.Ca)\n",
      " 1m 10s ( 30/52 )  (N)\n",
      " 1m 10s ( 31/52 )  (N)\n",
      " 1m 11s ( 32/52 )  (S.Sa.C.Ca)\n",
      " 1m 11s ( 33/52 )  (S.Sa.C.Ca)\n",
      " 1m 11s ( 34/52 )  (S.Sa.C.Ca)\n",
      " 1m 11s ( 35/52 )  (S.Sa.C.Ca)\n",
      " 1m 11s ( 36/52 )  (S.Sa.C.Ca)\n",
      " 1m 12s ( 37/52 )  (S.Sa.C.Ca)\n",
      " 1m 12s ( 38/52 )  (N)\n",
      " 1m 12s ( 39/52 )  (P.Pa)\n",
      " 1m 12s ( 40/52 )  (S.Sa.C.Ca)\n",
      " 1m 13s ( 41/52 )  (S.Sa.C.Ca)\n",
      " 1m 13s ( 42/52 )  (Hv.S.Sa.C.Ca)\n",
      " 1m 13s ( 43/52 )  (Hv.S.Sa)\n",
      " 1m 13s ( 44/52 )  (S.Sa)\n",
      " 1m 13s ( 45/52 )  (S.Sa)\n",
      " 1m 14s ( 46/52 )  (C.Ca)\n",
      " 1m 14s ( 47/52 )  (N)\n",
      " 1m 14s ( 48/52 )  (N)\n",
      " 1m 14s ( 49/52 )  (S.Sa)\n",
      " 1m 15s ( 50/52 )  (C.Ca)\n",
      " 1m 15s ( 51/52 )  (N)\n",
      " 1m 15s ( 52/52 )  (Pa)\n"
     ]
    }
   ],
   "source": [
    "filename = 'ROBchapter_8'\n",
    "\n",
    "\n",
    "import csv\n",
    "sticho_dict = collections.OrderedDict([])\n",
    "monad_list = []\n",
    "type_codes = {\"word\":\"W\", \"phrase_atom\":\"Pa\", \"clause_atom\":\"Ca\", \"sentence_atom\":\"Sa\", \"subphrase\":\"Sp\", \n",
    "              \"phrase\":\"P\",\"clause\":\"C\",\"sentence\":\"S\",\"half_verse\":\"Hv\", \"verse\": \"V\"}\n",
    "\n",
    "with open('{}.csv'.format(filename), 'r') as csvfile2:\n",
    "    readit = csv.reader(csvfile2)\n",
    "    for line in readit:\n",
    "        sticho_dict[int(line[0])] = [int(line[1]), line[2], line[3], line[4]]\n",
    "\n",
    "for key in sticho_dict:\n",
    "    monad_list.append([key,sticho_dict[key][0]])\n",
    "    \n",
    "\n",
    "sysct = 0\n",
    "for pair in monad_list:\n",
    "    lookup = '{}-{}'.format(pair[0],pair[1])\n",
    "    monads = tuple(int(x) for x in lookup.split('-'))\n",
    "    monad_list = [str(x) for x in range(monads[0], monads[1] +1)]\n",
    "    \n",
    "    #looks up every word between m_1 and m_2\n",
    "    monad_set = set(monad_list)\n",
    "    \n",
    "    lookedup = []\n",
    "    words = {}\n",
    "    \n",
    "\n",
    "    for node in nodes:\n",
    "        mon = F.monads.v(node)\n",
    "        if mon == lookup:\n",
    "            lookedup.append(node)\n",
    "        if mon in monad_set:\n",
    "            words[mon] = node\n",
    "    \n",
    "    otype_code = \"\"\n",
    "    \n",
    "    if lookedup != []:\n",
    "        dotct = len(lookedup)\n",
    "        for n in lookedup:\n",
    "            otype = F.otype.v(n)\n",
    "            if otype in type_codes:\n",
    "                dotct -= 1\n",
    "                if dotct > 0:\n",
    "                    otype_code += type_codes[otype]+\".\"\n",
    "                else:\n",
    "                    otype_code += type_codes[otype]\n",
    "    \n",
    "    else:\n",
    "        otype_code += \"N\"\n",
    "    \n",
    "    sticho_dict[pair[0]].append(otype_code)\n",
    "    sysct += 1\n",
    "    msg(\"( {}/{} )  ({})\".format(sysct,len(sticho_dict),otype_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 23s job finished! file saved.\n"
     ]
    }
   ],
   "source": [
    "with open('{}_coded.csv'.format(filename), 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    sysct = 0\n",
    "    for key in sticho_dict:\n",
    "        writer.writerow([sticho_dict[key][1]]+[key]+[sticho_dict[key][0]]+[sticho_dict[key][2]]+[sticho_dict[key][3]]+[sticho_dict[key][4]])\n",
    "msg(\"job finished! file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total stichoi = 52\n",
      "total none = 13\n",
      "25.0%\n",
      "['c', 'a', 'b', 'c', 'c', 'e', 'f', 'c', 'd', 'c', 'b', 'c', 'c']\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "totalN = 0\n",
    "types = []\n",
    "accents = []\n",
    "for key in sticho_dict:\n",
    "    total += 1\n",
    "    if sticho_dict[key][4] == \"N\":\n",
    "        types.append(sticho_dict[key][2])\n",
    "        accents.append(sticho_dict[key][3])\n",
    "        totalN += 1\n",
    "\n",
    "print (\"total stichoi = \" + (str(total)))\n",
    "print (\"total none = \" + (str(totalN)))\n",
    "print (str(round(float(totalN / total)*100,2)) + \"%\")\n",
    "print (types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
